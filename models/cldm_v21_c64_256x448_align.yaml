data:
  target: reconstruction_dataset.ReconstructionDataset
  params:
    prompt_path: '/SSD_DISK/data/nuscenes/All_in_occ/prompt.json'
    nuscenes_path: '/SSD_DISK/data/nuscenes/'
    pkl_path: '/SSD_DISK/data/nuscenes/nuscenes_occ_infos_train.pkl'
    mode: 'multi'
    with_hdmap: True
    one_hot: False
    return_mask: False
    input_size: [256, 448]
    cam_names: ['CAM_FRONT_LEFT', 'CAM_FRONT', 'CAM_FRONT_RIGHT', 'CAM_BACK_RIGHT', 'CAM_BACK', 'CAM_BACK_LEFT']

model:
  target: cldm.cldm.ControlLDM
  params:
    linear_start: 0.00085
    linear_end: 0.0120
    num_timesteps_cond: 1
    log_every_t: 200
    timesteps: 1000
    first_stage_key: "jpg"
    cond_stage_key: "txt"
    control_key: "hint"
    image_size: 64
    channels: 4
    cond_stage_trainable: false
    conditioning_key: crossattn
    monitor: val/loss_simple_ema
    scale_factor: 0.18215
    use_ema: False
    view_num: 6
    only_mid_control: False
    cfg_scale: 9.0
    input_size: [256, 448]
    origin_occ_shape: [ 16, 200, 200 ]
    down_sample: 8
    use_multi_view_attn: False
    grid_config:
      x_bound: [-40.0, 40.0, 0.4]
      y_bound: [-40.0, 40.0, 0.4]
      z_bound: [-1.0, 5.4, 0.4]
      d_bound: [0.5, 48.5, 1.0]


    control_stage_config:
      target: cldm.cldm.ControlNet
      params:
        use_checkpoint: True
        image_size: 32 # unused
        in_channels: 4
        hint_channels: 64
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_head_channels: 64 # need to fix for flash-attn
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024
        legacy: False

    unet_config:
      target: cldm.cldm.ControlledUnetModel
      params:
        use_checkpoint: True
        image_size: 32 # unused
        in_channels: 4
        out_channels: 4
        model_channels: 320
        attention_resolutions: [ 4, 2, 1 ]
        num_res_blocks: 2
        channel_mult: [ 1, 2, 4, 4 ]
        num_head_channels: 64 # need to fix for flash-attn
        use_spatial_transformer: True
        use_linear_in_transformer: True
        transformer_depth: 1
        context_dim: 1024
        legacy: False
        use_multi_view_attn: False
        with_position: False  
        use_local: False

    occ_encoder_config:
      target: cldm.encoders.OccupancyEncoder
      params:
        # input_channel: 24
        input_channel: 8
        norm_cfg: 
          type: 'GN'
          num_groups: 16 
          requires_grad: True
        base_channel: 128
        out_channel: 64
        sparse_shape_xyz: [200, 200, 16]

    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ddconfig:
          #attn_type: "vanilla-xformers"
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

    cond_stage_config:
      target: ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder
      params:
        freeze: True
        layer: "penultimate"
